{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Python API Training - Advanced Feature Manipulation [Exercise]\n",
    "\n",
    "<b>Author:</b> Thodoris Petropoulos <br>\n",
    "<b>Contributors:</b> Rajiv Shah\n",
    "\n",
    "This is the 2nd exercise to complete in order to finish your `Python API Training for DataRobot` course! This exercise will help you learn how to do advanced feature manipulation to increase model accuracy and make your models more parsimonious by reducing the numbers of features they are using.\n",
    "\n",
    "Here are the actual sections of the notebook alongside time to complete: \n",
    "\n",
    "1. Connect to DataRobot. [3min]<br>\n",
    "2. Retrieve the Project created during the `Feature Selection Curves` exercise. [5min]<br>\n",
    "3. Retrieve FI for the top 5 models trained on the `Informative Features` Feature list. [30min]<br>\n",
    "4. Plot the top 5 features by median FI scores. Then create two lists with top 10 and top 20 features.[15min]\n",
    "5. Run the best non-blender model using 100% of the sample data on the newly created feature lists. [7min]\n",
    "6. Compare the newly trained models. Which one has the highest AUC validation score?. [7min]\n",
    "7. Bonus Question.\n",
    "\n",
    "Each section will have specific instructions so do not worry if things are still blurry!\n",
    "\n",
    "As always, consult:\n",
    "\n",
    "- [API Documentation](https://datarobot-public-api-client.readthedocs-hosted.com)\n",
    "- [Samples](https://github.com/datarobot-community/examples-for-data-scientists)\n",
    "- [Tutorials](https://github.com/datarobot-community/tutorials-for-data-scientists)\n",
    "\n",
    "The last two links should provide you with the snippets you need to complete most of these exercises.\n",
    "\n",
    "<b>Data</b>\n",
    "\n",
    "The dataset we will be using throughout these exercises is the well-known `readmissions dataset`. You can access it or directly download it through DataRobot's public S3 bucket [here](https://s3.amazonaws.com/datarobot_public_datasets/10k_diabetes.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "Import libraries here as you start finding out what libraries are needed. The DataRobot package is already included for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datarobot as dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Connect to DataRobot [3min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Retrieve the Project created during the `Feature Selection Curves` exercise. [5min]<br>\n",
    "\n",
    "Retrieve the project you created using the readmissions dataset and save it into a variable called `project`.\n",
    "\n",
    "**Hint 1**: To use a project created in DataRobot you can either list all of the available projects using the Python api or find the ID from the web interface. For example, if you are logged into DataRobot, your browser will be pointing to a link such as this: `https//:YOUR_HOSTNAME/projects/PROJECT_ID/models/MODEL_ID`. Just copy paste the `PROJECT_ID`.\n",
    "\n",
    "**Hint 2**: Check the `datarobot.Project.get` method. That should help you retrieve your DataRobot project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Retrieve FI for the top 5 models trained on the `Informative Features` Feature list. [30min]<br>\n",
    "\n",
    "**Instructions**:\n",
    "- Create a list of the top 5 models based on the `validation` score.\n",
    "- Make sure that these models have been trained using the `informative features` list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plot the top 5 features by median FI scores. Then create two lists with top 10 and top 20 features.[15min]\n",
    "\n",
    "**Instructions**\n",
    "1. Aggregate the results you retrieved from Feature Impact to calculate the top 10 and top 20 features. \n",
    "2. Create two DataRobot feature lists `top_10_aggregated` and `top_20_aggregated`.\n",
    "3. Plot the top 10 features with their FI score.\n",
    "\n",
    "**Hint**: There is some sample code for plotting Feature Impact within [Samples](https://github.com/datarobot-community/examples-for-data-scientists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We basically bult a 'wisdom of the crowds' process that provides us with the most impactful features based on multiple models. We could also run the same process between projects with different seeds. This can be especially helpful in wide datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run the best non-blender model using 100% of the sample data on the newly created feature lists. [7min]\n",
    "\n",
    "**Hint**: You will first need to unlock project holdout to be able to train the models on 100% of the data.\n",
    "\n",
    "**Hint 2**: Do not forget to wait until your modelâ€™s training is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compare the newly trained models. Which one has the highest AUC validation score?. [7min]\n",
    "\n",
    "1. Query all of the models.\n",
    "2. Find the models that we need (trained on the specific feature lists.\n",
    "3. Print the accuracy metric for each one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification\n",
    "To verify that you have completed everything correctly, look at the AUC Validation score for the best model when trained on the new featurelists. Is the highest AUC `0.70`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Question\n",
    "\n",
    "1. Why is the number of models trained more than 2? Can you guess? \n",
    "2. Combine the result from the Feature Impact exercise with the feature association matrix. What is the average Feature Impact per cluster? Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
