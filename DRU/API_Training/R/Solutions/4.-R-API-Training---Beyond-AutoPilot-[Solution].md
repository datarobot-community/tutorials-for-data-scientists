4\. R API Training - Beyond AutoPilot \[Solution\]
================
Thodoris Petropoulos and Chester Ismay<br>Contributors: Rajiv Shah

This is the 4th exercise to complete in order to finish your `R API
Training for DataRobot` course\! This exercise will help you learn how
to use the repository and advanced tuning to create models that are
better than the autopilot.

Here are the actual sections of the notebook alongside time to complete:

1.  Connect to DataRobot. \[3min\]<br>
2.  Retrieve the Project created during the `Feature Selection Curves`
    exercise. \[5min\]<br>
3.  Retrieve validation and cross-validation AUC score for best current
    model. \[7min\]
4.  Run models with `Keras` within their `model_type` (64 `sample_pct`).
    \[15min\]
5.  Check whether you created a model with a better validation score.
    \[10min\]
6.  Sort all models by cross validation score. \[15min\]
7.  Retrieve a specific model and change a specific hyperparameter.

Each section will have specific instructions so do not worry if things
are still blurry\!

As always, consult:

  - [API Documentation via CRAN
    Vignettes](https://CRAN.R-project.org/package=datarobot)
  - [Samples](https://github.com/datarobot-community/examples-for-data-scientists)
  - [Tutorials](https://github.com/datarobot-community/tutorials-for-data-scientists)

The last two links should provide you with the snippets you need to
complete most of these exercises.

<b>Data</b>

The dataset we will be using throughout these exercises is the
well-known `readmissions dataset`. You can access it or directly
download it through DataRobotâ€™s public S3 bucket
[here](https://s3.amazonaws.com/datarobot_public_datasets/10k_diabetes.csv).

### Import Packages

Import packages here as you start finding out what packages are needed.
The DataRobot package is already included for your convenience.

``` r
#Proposed packages needed
library(dplyr)
```

    ## 
    ## Attaching package: 'dplyr'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     filter, lag

    ## The following objects are masked from 'package:base':
    ## 
    ##     intersect, setdiff, setequal, union

``` r
library(purrr)
```

### 1\. Connect to DataRobot \[3min\]

``` r
# Possible solution
datarobot::ConnectToDataRobot(configPath = "../config.yaml")
```

``` r
# After connecting, load the datarobot package
library(datarobot)
```

### 2\. Retrieve the Project created during the `Feature Selection Curves` exercise. \[5min\]<br>

Retrieve the project you created using the readmissions dataset and save
it into a variable called `project`.

**Hint**: To use a project created in DataRobot you can either list all
of the available projects using the R api or find the ID from the web
interface. For example, if you are logged into DataRobot, your browser
will be pointing to a link such as this:
`https//:YOUR_HOSTNAME/projects/PROJECT_ID/models/MODEL_ID`. Just copy
and paste the `PROJECT_ID`.

``` r
#Proposed Solution
project <- GetProject('YOUR_PROJECT_ID')
```

### 3\. Retrieve validation and cross-validation AUC score for best current model. \[7min\]

``` r
# Proposed Solution
best_model <- ListModels(project)[[1]]

best_model
```

    ## $blueprintId
    ## [1] "1fdcdec49052b3465c054514f31a196d"
    ## 
    ## $featurelistId
    ## [1] "5f3567119071ae52e2b632d2"
    ## 
    ## $featurelistName
    ## [1] "top_20_aggregated"
    ## 
    ## $isFrozen
    ## [1] FALSE
    ## 
    ## $isStarred
    ## [1] FALSE
    ## 
    ## $metrics
    ## $metrics$AUC
    ##   backtesting holdout backtestingScores crossValidation validation
    ## 1          NA 0.70393                NA        0.708082     0.7089
    ## 
    ## $metrics$`Rate@Top5%`
    ##   backtesting holdout backtestingScores crossValidation validation
    ## 1          NA    0.69                NA          0.7575      0.675
    ## 
    ## $metrics$`Max MCC`
    ##   backtesting holdout backtestingScores crossValidation validation
    ## 1          NA 0.29777                NA         0.31126    0.33336
    ## 
    ## $metrics$RMSE
    ##   backtesting holdout backtestingScores crossValidation validation
    ## 1          NA  0.4587                NA        0.457156    0.45881
    ## 
    ## $metrics$`Kolmogorov-Smirnov`
    ##   backtesting holdout backtestingScores crossValidation validation
    ## 1          NA 0.30431                NA        0.312244    0.34066
    ## 
    ## $metrics$`Rate@TopTenth%`
    ##   backtesting holdout backtestingScores crossValidation validation
    ## 1          NA     0.5                NA             0.9          1
    ## 
    ## $metrics$LogLoss
    ##   backtesting holdout backtestingScores crossValidation validation
    ## 1          NA 0.60725                NA        0.604764     0.6081
    ## 
    ## $metrics$`FVE Binomial`
    ##   backtesting holdout backtestingScores crossValidation validation
    ## 1          NA 0.09578                NA        0.099476    0.09472
    ## 
    ## $metrics$`Gini Norm`
    ##   backtesting holdout backtestingScores crossValidation validation
    ## 1          NA 0.40786                NA        0.416164     0.4178
    ## 
    ## $metrics$`Rate@Top10%`
    ##   backtesting holdout backtestingScores crossValidation validation
    ## 1          NA    0.69                NA          0.7375    0.66875
    ## 
    ## 
    ## $modelCategory
    ## [1] "model"
    ## 
    ## $modelType
    ## [1] "eXtreme Gradient Boosted Trees Classifier with Early Stopping"
    ## 
    ## $monotonicDecreasingFeaturelistId
    ## NULL
    ## 
    ## $monotonicIncreasingFeaturelistId
    ## NULL
    ## 
    ## $predictionThreshold
    ## [1] 0.5
    ## 
    ## $predictionThresholdReadOnly
    ## [1] FALSE
    ## 
    ## $processes
    ## [1] "Ordinal encoding of categorical variables"                    
    ## [2] "Converter for Text Mining"                                    
    ## [3] "Auto-Tuned Word N-Gram Text Modeler using token occurrences"  
    ## [4] "Missing Values Imputed"                                       
    ## [5] "eXtreme Gradient Boosted Trees Classifier with Early Stopping"
    ## 
    ## $projectId
    ## [1] "5f355e8fc541da0ff3236dc8"
    ## 
    ## $samplePct
    ## [1] 100
    ## 
    ## $supportsMonotonicConstraints
    ## [1] TRUE
    ## 
    ## $trainingRowCount
    ## [1] 10000
    ## 
    ## $projectName
    ## [1] "01_Feature_Selection_Curves"
    ## 
    ## $projectTarget
    ## [1] "readmitted"
    ## 
    ## $projectMetric
    ## [1] "AUC"
    ## 
    ## $modelId
    ## [1] "5f356719735d1f5293365b0e"
    ## 
    ## attr(,"class")
    ## [1] "dataRobotModel"

``` r
best_model$metrics$AUC$validation
```

    ## [1] 0.7089

``` r
best_model$metrics$AUC$crossValidation
```

    ## [1] 0.708082

### 4\. Run models with `Keras` within their `modelType` (64 `samplePct`). \[15min\]

Run the first 3 available Keras blueprints with the default Informative
Features featurelist.

**Hint** To see models that are in the repository, call the
`ListBlueprints()` function on the DataRobot Project object.

``` r
# Proposed Solution
blueprints <- ListBlueprints(project)

keras_bps <- Filter(function(bp) grepl("Keras", bp$modelType),
                    blueprints)

keras_to_train <- keras_bps[1:3]

job_ids <- vector(mode = "character", length = 3)
for (i in seq_along(keras_to_train)) 
    job_ids[i] <- RequestNewModel(
        project,
        blueprint = keras_to_train[[i]],
        samplePct = 64,
    )
```

    ## New model request received
    ## New model request received
    ## New model request received

``` r
for (j in seq_along(job_ids))
    WaitForJobToComplete(project, jobId = job_ids[j])
```

### 5\. Check whether you created a model with a better validation score. \[10min\]

**Hint**": You will have to ask DataRobot to send you the latest models
again to see which is the current best model.

``` r
# Proposed Solution
best_model <- ListModels(project)[[1]]

best_model$metrics$AUC$validation
```

    ## [1] 0.7089

``` r
best_model$metrics$AUC$crossValidation
```

    ## [1] 0.708082

### 6\. Sort models by cross validation score. \[15min\]

**Hint**: Cross validation will not be calculated for all of the models.
You can choose to calculate cross validation first for all models or
just sort by crossValidation for the ones that have cross validation
available (to save time).

**Hint2**: One way to accomplish this is to create a function that
extracts different entries from the leaderboard for each model. Then
iterate over this function using `map_dfr()` from the {purrr} package
and sort based on cross validation values in the resulting data frame.

``` r
# Proposed Solution

models <- ListModels(project)

extract_components <- function (model) {
    model_type <- model$modelType
    featurelist <- if_else(is.null(model$featurelistName),
                           "Multiple Feature Lists",
                           model$featurelistName)
    sample_pct <- model$samplePct
    cv <- model$metrics$AUC$crossValidation
    data.frame(model_type, featurelist, sample_pct, cv)
}

names_and_cv <- map_dfr(models, extract_components) %>% 
    arrange(desc(cv))
```

### 7\. Retrieve a specific model and change a specific hyperparameter.

**Instructions**:

Find the model with the below characteristics:

  - Model Type = `eXtreme Gradient Boosted Trees Classifier with Early
    Stopping`
  - Featurelist = `Informative Features`
  - Sample Percentage = 64

Tune:

  - Change `learning_rate` to 0.2

**Hint**: There is a script in
[Samples](https://github.com/datarobot-community/examples-for-data-scientists)
that can help you with hyperparameter tuning.

``` r
# Proposed Solution
isolate_on_criteria <- function (model) {
    model_match <- model$modelType == "eXtreme Gradient Boosted Trees Classifier with Early Stopping"
    fl_match <- model$featurelistName == "Informative Features"
    model_match & !is.null(fl_match)
}
model_to_tune <- Filter(isolate_on_criteria, models)[[1]]

#Start tuning procedure by creating a function we'll call `tune` here
tune <- StartTuningSession(model_to_tune)

# List of parameters available for tuning
parameters <- GetTuningParameters(model_to_tune)
summary(parameters)
```

    ##                      name   current default
    ## 1                  arbimp     -9999   -9999
    ## 2            min_count_na         5       5
    ## 3                card_max      None    None
    ## 4                  method      freq    freq
    ## 5             min_support         5       5
    ## 6  base_margin_initialize     False   False
    ## 7       colsample_bylevel         1       1
    ## 8        colsample_bytree       0.3     0.3
    ## 9                interval        10      10
    ## 10          learning_rate      0.05    0.05
    ## 11                max_bin       256     256
    ## 12         max_delta_step         0       0
    ## 13              max_depth [3, 5, 7]       7
    ## 14       min_child_weight         1       1
    ## 15         min_split_loss      0.01    0.01
    ## 16          missing_value     -9999   -9999
    ## 17           n_estimators      2500    2500
    ## 18      num_parallel_tree         1       1
    ## 19           random_state      1234    1234
    ## 20              reg_alpha         0       0
    ## 21             reg_lambda         1       1
    ## 22       scale_pos_weight         1       1
    ## 23        smooth_interval       200     200
    ## 24              subsample         1       1
    ## 25            tree_method      auto    auto
    ##                                    constraint
    ## 1                             -99999 to 99999
    ## 2                                  0 to 99999
    ## 3           1 to 9999999 or select from: None
    ## 4  select from: None, random, lex, freq, resp
    ## 5                                  1 to 99999
    ## 6                    select from: False, True
    ## 7                                    0.1 to 1
    ## 8                                   0.05 to 1
    ## 9                                    2 to 500
    ## 10                                 5e-04 to 1
    ## 11                                 16 to 2048
    ## 12                                   0 to 100
    ## 13                                    1 to 16
    ## 14                              0.01 to 1e+05
    ## 15                                 0 to 1e+05
    ## 16                            -1e+05 to 1e+05
    ## 17                                 1 to 20000
    ## 18                                    1 to 16
    ## 19                            0 to 1000000000
    ## 20                                 0 to 1e+06
    ## 21                                 0 to 1e+06
    ## 22                                 0 to 1e+09
    ## 23                                  2 to 1000
    ## 24                                  0.01 to 1
    ## 25     select from: auto, exact, approx, hist

``` r
#Now that we know the name of the variable we want to change is `learning_rate`, 
#we can use the tune() function that was created above from 
#`StartTuningSession()` to start training this tuned model.
tuning_job <- tune(model_to_tune, learning_rate = 0.2)

#Get model
tuned_model <- GetModelFromJobId(project, modelJobId = tuning_job)
```

    ## Model request issued: awaiting response

    ## Model 5f36d57c735d1f5d6a365a7d retrieved

``` r
tuned_model$metrics$AUC$validation
```

    ## [1] 0.69282
