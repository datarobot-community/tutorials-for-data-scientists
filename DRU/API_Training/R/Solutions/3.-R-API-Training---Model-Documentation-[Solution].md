3\. R API Training - Model Documentation \[Solution\]
================
Thodoris Petropoulos and Chester Ismay<br>Contributors: Rajiv Shah

This is the 3rd exercise to complete in order to finish your `R API
Training for DataRobot` course\! This exercise will help you learn how
to retrieve model insights using the R API. These insights are normally
readily available through the UI but you can also retrieve the raw
results.

Here are the actual sections of the notebook alongside time to complete:

1.  Connect to DataRobot. \[3min\]<br>
2.  Retrieve the Project created during the `Feature Selection Curves`
    exercise. \[5min\]<br>
3.  Plot Feature Impact for any trained model. Show the model’s
    blueprint.\[10min\]
4.  Plot any word cloud results. \[10min\]
5.  Plot ROC Curve data for the validation partition. \[10min\]
6.  Plot Lift Chart for the validation partition. \[10min\]
7.  Compute Prediction explanations for the training dataset. \[10min\]
8.  Bonus Question.

Each section will have specific instructions so do not worry if things
are still blurry\!

As always, consult:

  - [API Documentation via CRAN
    Vignettes](https://CRAN.R-project.org/package=datarobot)
  - [Samples](https://github.com/datarobot-community/examples-for-data-scientists)
  - [Tutorials](https://github.com/datarobot-community/tutorials-for-data-scientists)

The last two links should provide you with the snippets you need to
complete most of these exercises.

<b>Data</b>

The dataset we will be using throughout these exercises is the
well-known `readmissions dataset`. You can access it or directly
download it through DataRobot’s public S3 bucket
[here](https://s3.amazonaws.com/datarobot_public_datasets/10k_diabetes.csv).

### Import Packages

Import packages here as you start finding out what packages are needed.
The DataRobot package is already included for your convenience.

``` r
#Proposed packages needed
library(dplyr)
```

    ## 
    ## Attaching package: 'dplyr'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     filter, lag

    ## The following objects are masked from 'package:base':
    ## 
    ##     intersect, setdiff, setequal, union

``` r
library(ggplot2)
library(DiagrammeR)
library(modelwordcloud)
library(purrr)
```

### 1\. Connect to DataRobot \[3min\]

``` r
#Possible solution
datarobot::ConnectToDataRobot(configPath = '../config.yaml')
```

    ## Authentication token saved

``` r
library(datarobot)
```

    ## Authenticating with config at: /Users/chester.ismay/.config/datarobot/drconfig.yaml
    ## Authentication token saved

### 2\. Retrieve the Project created during the `Feature Selection Curves` exercise. \[5min\]<br>

Retrieve the project you created using the readmissions dataset and save
it into a variable called `project`.

**Hint**: To use a project created in DataRobot you can either list all
of the available projects using the R api or find the ID from the web
interface. For example, if you are logged into DataRobot, your browser
will be pointing to a link such as this:
`https//:YOUR_HOSTNAME/projects/PROJECT_ID/models/MODEL_ID`. Just copy
paste the `PROJECT_ID`.

``` r
#Proposed Solution
project <- GetProject('YOUR_PROJECT_ID')
```

### 3\. Plot Feature Impact for any trained model. Show the model’s blueprint chart information.\[10min\]

**Hint**: Modify your code from the previous exercise to produce a
Feature Impact plot for a single model showing the top 10 features in
terms of Feature Impact.

**Hint 2**: Use the `GetModelBlueprintChart()` function for a high level
representation of the Blueprint and `BlueprintChartToGraphviz()` to
convert it to a graph format. Check out the `grViz()` function in the
{DiagrammeR} package to produce a visual of the blueprint.

``` r
#Proposed Solution

#Retrieve a datarobot model object
model <- ListModels(project)[[1]]

#Get Feature Impact as a data frame
feature_impact <- GetFeatureImpact(model)

ggplot(data = feature_impact %>% head(5),
       mapping = aes(x = reorder(featureName, -impactNormalized),
                     y = impactNormalized)) +
  geom_col(fill = "forestgreen") +
  labs(x = "Feature",
       y = "Impact")
```

![](3.-R-API-Training---Model-Documentation-%5BSolution%5D_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

``` r
bp_chart_specs <- GetModelBlueprintChart(project, modelId = model$modelId) %>% 
  BlueprintChartToGraphviz()

grViz(bp_chart_specs)
```

![](3.-R-API-Training---Model-Documentation-%5BSolution%5D_files/figure-gfm/unnamed-chunk-5-2.png)<!-- -->

### 4\. Plot any word cloud results. \[10min\]

**Hint**: The function to retrieve the word cloud is `GetWordCloud()`
and it is applied on a DataRobot Model object but not all of the models
have a word cloud. Try to create a process that checks whether a model
has a word cloud available and return the first available data.

**Hint 2**: There is sample script of how to plot word cloud data within
[Samples](https://github.com/datarobot-community/examples-for-data-scientists)
under Model Evaluation.

``` r
#Proposed Solution

#Save all models
models <- ListModels(project)

#Check for word cloud
for (model in models) {
  # try() will return a try-catch class object if
  # a word cloud is not available for a model
  # It returns a data.frame object if a word cloud is available
  if ("data.frame" %in% class(try(
    expr = {
      wc_data <- GetWordCloud(
        project, 
        modelId = model$modelId,
        excludeStopWords = TRUE)
    },
    silent = TRUE))) {
    break
  }
}
wc_data$ngram[1:2]
```

    ## [1] "hepatic"  "calculus"

``` r
# Colors similar to what DataRobot gives
dr_colors <- c(
  colormap::colormap(c("#255FEC", "#2DBEF9")), 
  colormap::colormap(
    c("#FFAC9D", "#D80909"), 
    reverse = TRUE
  )
)

# Plot Wordcloud
wordcloud(
  words = wc_data$ngram,
  freq = wc_data$frequency,
  coefficients = wc_data$coefficient,
  colors = dr_colors,
  scale = c(3, 0.3))
```

![](3.-R-API-Training---Model-Documentation-%5BSolution%5D_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->

### 5\. Plot ROC Curve data for the validation partition. \[10min\]

**Hint**: After retrieving ROC data, call
`pd.DataFrame(roc_data.roc_points)` function to transform the results
into something easier to the eye.

**Hint 2**: There is a sample script of how to plot the ROC curve within
[Samples](https://github.com/datarobot-community/examples-for-data-scientists)
under Model Evaluation.

``` r
# Proposed Solution

model <- ListModels(project)[[1]]

#Get roc_curve data
roc_data <- GetRocCurve(model, source = 'validation')

# Extract the data frame of the data
roc_df <- roc_data$rocPoints
head(roc_df)
```

    ##   fractionPredictedAsPositive falseNegativeScore falsePositiveRate
    ## 1                    0.000000                635       0.000000000
    ## 2                    0.001250                633       0.000000000
    ## 3                    0.001875                632       0.000000000
    ## 4                    0.004375                630       0.002072539
    ## 5                    0.010000                625       0.006217617
    ## 6                    0.019375                615       0.011398964
    ##   trueNegativeScore truePositiveScore matthewsCorrelationCoefficient
    ## 1               965                 0                     0.00000000
    ## 2               965                 2                     0.04361174
    ## 3               965                 3                     0.05342997
    ## 4               963                 5                     0.04300631
    ## 5               959                10                     0.04686242
    ## 6               954                20                     0.07133318
    ##   liftNegative trueNegativeRate fractionPredictedAsNegative threshold
    ## 1     1.000000        1.0000000                    1.000000 1.0000000
    ## 2     1.001252        1.0000000                    0.998750 0.8527783
    ## 3     1.001879        1.0000000                    0.998125 0.8452571
    ## 4     1.002313        0.9979275                    0.995625 0.7971350
    ## 5     1.003821        0.9937824                    0.990000 0.7713556
    ## 6     1.008134        0.9886010                    0.980625 0.7532005
    ##   liftPositive positivePredictiveValue negativePredictiveValue
    ## 1     0.000000               0.0000000               0.6031250
    ## 2     2.519685               1.0000000               0.6038798
    ## 3     2.519685               1.0000000               0.6042580
    ## 4     1.799775               0.7142857               0.6045198
    ## 5     1.574803               0.6250000               0.6054293
    ## 6     1.625603               0.6451613               0.6080306
    ##   falsePositiveScore truePositiveRate     f1Score accuracy
    ## 1                  0      0.000000000 0.000000000 0.603125
    ## 2                  0      0.003149606 0.006279435 0.604375
    ## 3                  0      0.004724409 0.009404389 0.605000
    ## 4                  2      0.007874016 0.015576324 0.605000
    ## 5                  6      0.015748031 0.030721966 0.605625
    ## 6                 11      0.031496063 0.060060060 0.608750

``` r
# Plot ROC Curve
dr_dense_green <- '#018f4f'

ggplot(data = roc_df,
       mapping = aes(x = falsePositiveRate, y = truePositiveRate)) + 
  geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), 
               color = "grey30") +
  geom_line(color = dr_dense_green) +
  xlim(0, 1) +
  ylim(0, 1) +
  labs(x = "False Positive Rate (Fallout)",
       y = "True Positive Rate (Sensitivity)") +
  ggtitle("ROC curve") +
  theme_minimal()
```

![](3.-R-API-Training---Model-Documentation-%5BSolution%5D_files/figure-gfm/unnamed-chunk-9-1.png)<!-- -->

### 6\. Plot Lift Chart for the validation partition. \[10min\]

**Hint**: There is a sample script of how to plot the lift chart within
[Samples](https://github.com/datarobot-community/examples-for-data-scientists)
under Model Evaluation.

``` r
#Proposed Solution
lc <- GetLiftChart(model, source = "validation")

# Stack columns to get into tidy format
# Could also use `pivot_longer()` from {tidyr} here
lc_modified <- data.frame(
  average_target_value = c(lc$actual, lc$predicted),
  variable = c(rep("Actual", length(lc$actual)),
               rep("Predicted", length(lc$predicted))),
  bin = rep(seq_along(lc$actual), 2)
)

# Plot Lift Chart with 60 bins
ggplot(data = lc_modified,
       mapping = aes(x = bin, y = average_target_value, color = variable)) +
  geom_point() +
  geom_line()
```

![](3.-R-API-Training---Model-Documentation-%5BSolution%5D_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->

### 7\. Compute Prediction Explanations for the training dataset. \[10min\]

**Hint**: Similarly to before, there is a sample script of how to
compute prediction explanations within
[Samples](https://github.com/datarobot-community/examples-for-data-scientists).

``` r
#Proposed Solution

#Calculate FI in case it's not calculated
fi <- GetFeatureImpact(model)

#Uploading Training dataset
dataset_from_path <- UploadPredictionDataset(
  project,
  dataSource = 'https://s3.amazonaws.com/datarobot_public_datasets/10k_diabetes.csv'
)

#Request predictions
predict_job <- RequestPredictions(
    project,
    modelId = model$modelId,
    datasetId = dataset_from_path$id
)

#Get prediction calculations
predictions <- GetPredictions(
    project,
    predictId = predict_job,
    type = "raw"
)
```

    ## request issued, waiting for predictions

``` r
head(predictions)
```

    ##                             predictionValues predictionThreshold prediction
    ## 1         0.27294, 0.72706, 1.00000, 0.00000                 0.5          0
    ## 2 0.2006608, 0.7993392, 1.0000000, 0.0000000                 0.5          0
    ## 3     0.566591, 0.433409, 1.000000, 0.000000                 0.5          1
    ## 4 0.1208845, 0.8791155, 1.0000000, 0.0000000                 0.5          0
    ## 5 0.2042228, 0.7957772, 1.0000000, 0.0000000                 0.5          0
    ## 6 0.4053764, 0.5946236, 1.0000000, 0.0000000                 0.5          0
    ##   rowId positiveProbability
    ## 1     0           0.2729400
    ## 2     1           0.2006608
    ## 3     2           0.5665910
    ## 4     3           0.1208845
    ## 5     4           0.2042228
    ## 6     5           0.4053764

``` r
#Initiate prediction explanations
pe_init_id <- RequestPredictionExplanationsInitialization(model)
```

    ## Prediction explanations initialization requested for model eXtreme Gradient Boosted Trees Classifier with Early Stopping (modelId =  5f356719735d1f5293365b0e )

``` r
WaitForJobToComplete(project, jobId = pe_init_id)
pe_job_id <- RequestPredictionExplanations(
    model, 
    datasetId = dataset_from_path$id
)
```

    ## Prediction explanations requested for model eXtreme Gradient Boosted Trees Classifier with Early Stopping (modelId =  5f356719735d1f5293365b0e )

``` r
pe_meta_id <- GetPredictionExplanationsMetadataFromJobId(
        project, 
        jobId = pe_job_id
)$id
```

    ## Prediction explanations request issued: awaiting response

``` r
pe_list <- GetPredictionExplanationsRows(
    project, 
    predictionExplanationId = pe_meta_id
)
#Extract all prediction explanations
pe <- map(pe_list, "predictionExplanations")
```

### Verification

The first n-gram that is generated should be `hepatic` and the
coefficient value should be around `0.1703`. Did you have the same
result?

### 8\. Bonus Question

DataRobot provides automated model documentation. Try to create and
download the `Compliance Documentation` DOCX file.

``` r
# Proposed Solution

# Using the default template
DownloadComplianceDocumentation(
  model, 
  filename = "Top Model Documentation.docx"
)
```
