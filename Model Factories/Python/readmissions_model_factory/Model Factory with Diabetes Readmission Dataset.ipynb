{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](media/DataRobot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Predictive Model Factory\n",
    "\n",
    "**Author**: Thodoris Petropoulos\n",
    "\n",
    "#### Definition\n",
    "\n",
    "A model factory, in the context of data science, is a system, or a set of procedures that automatically generate predictive models with little or no human intervention. Model factories can have multiple layers of complexity which we can call modules. One module might be training models while other modules could be deploying or retraining the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How would you tackle this?\n",
    "\n",
    "#### - Consider the scenario where you have 20.000 SKUs  and you need to do sales forecasting for each one of them.\n",
    "#### - Consider the scenario where you have multiple types of customers and you are trying to predict churners.\n",
    "\n",
    "- Can one model handle the high dimentionality that comes with these problems?\n",
    "- Is a single model family enough?\n",
    "- Is one preprocessing method enough?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataRobot Model Factory\n",
    "\n",
    "In short:\n",
    "- Use DataRobot to build a single project on the readmissions  dataset.\n",
    "- Find best model for this project.\n",
    "- Use DataRobot to build multiple projects based on admission id.\n",
    "- Find best model for each of the sub-projects\n",
    "- Make best models ready for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datarobot as dr #Requires version >2.19\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Functions\n",
    "Functions that will be used to plot the ROC curve and Feature Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(datarobot_model):\n",
    "    \"\"\"This function plots a roc curve.\n",
    "    Input:\n",
    "        datarobot_model: <Datarobot Model object>\n",
    "    \"\"\"\n",
    "    roc = datarobot_model.get_roc_curve('crossValidation')\n",
    "    roc_df = pd.DataFrame(roc.roc_points)\n",
    "    auc_score = datarobot_model.metrics['AUC']['crossValidation']\n",
    "    plt.plot(roc_df['false_positive_rate'], roc_df['true_positive_rate'], 'b', label = 'AUC = %0.2f' %auc_score)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_impact(datarobot_model, title=None):\n",
    "    \"\"\"This function plots feature impact\n",
    "    Input:\n",
    "        datarobot_model: <Datarobot Model object>\n",
    "        title : <string> --> title of graph\n",
    "    \"\"\"\n",
    "    #Get feature impact\n",
    "    feature_impacts = datarobot_model.get_or_request_feature_impact()\n",
    "\n",
    "    #Sort feature impact based on normalised impact\n",
    "    feature_impacts.sort(key=lambda x: x['impactNormalized'], reverse=True)\n",
    "\n",
    "    fi_df = pd.DataFrame(feature_impacts) #Save feature impact in pandas dataframe\n",
    "    fig, ax = plt.subplots(figsize=(14,5))\n",
    "    b = sns.barplot(x=\"featureName\", y=\"impactNormalized\", data=fi_df[0:5], color=\"b\")\n",
    "    b.axes.set_title('Feature Impact' if not title else title,fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "df = pd.read_excel('data/10k_diabetes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to DataRobot\n",
    "Connect to DataRobot using your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'YOUR_DATAROBOT_HOST'\n",
    "api_token = 'YOUR_API_KEY'\n",
    "dr.Client(token=api_token, endpoint=endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate DataRobot project for all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_proj = dr.Project.start(df,                                       #Pandas dataframe with data\n",
    "                                project_name = 'Readmissions',             # Name of the project\n",
    "                                target = 'readmitted',                     #Target of the project\n",
    "                                metric = 'LogLoss',                        #Optimization metric (Default is LogLoss anyways)\n",
    "                                worker_count = -1)                         #Amount of workers to use (-1 means every worker available)\n",
    "\n",
    "log = original_proj.wait_for_autopilot() #Wait for autopilot to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get best model from original project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick best model\n",
    "best_model = original_proj.get_models()[0]\n",
    "\n",
    "print(best_model) #Print best model's name\n",
    "best_model.metrics['LogLoss']['crossValidation'] #Print crossValidation score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Feature Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_impact(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a better model\n",
    "Admission type can be used as a splitting point in order to create multiple projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "c = sns.countplot(x=\"admission_type_id\",data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a mini model factory\n",
    "Using a for loop to automatically create multiple projects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = {} #To save projects\n",
    "\n",
    "#Create one project for each customer type\n",
    "for value in df['admission_type_id'].unique():\n",
    "    try:\n",
    "        temp_project = dr.Project.start(df.loc[df['admission_type_id'] == value],\n",
    "                                    project_name = 'Readmission_%s'%value,\n",
    "                                    target = 'readmitted',\n",
    "                                    metric = 'LogLoss',\n",
    "                                    worker_count = 10)\n",
    "        projects[value] = temp_project\n",
    "\n",
    "    except: #Catching the case when dataset has fewer than 20 rows.\n",
    "        pass\n",
    "#Wait for all autopilots to finish\n",
    "for key in projects:\n",
    "    log = projects[key].wait_for_autopilot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting best model for each customer category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {} #To save models\n",
    "for key in projects:\n",
    "    best_models[key] = projects[key].get_models()[0]\n",
    "    print('--------------------------------')\n",
    "    print('Best model for admission type id: %s' %key)\n",
    "    print(best_models[key])\n",
    "    print(best_models[key].metrics['LogLoss']['crossValidation'])\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Even though accuracy changes might be insignificant for this dataset, in cases where it makes sense, model factory can produce measurable value. Furthermore, this concept becomes more and more important the higher the cardinality of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Its not just about more predictive performance....\n",
    "We also have differences in feature impact which could give actionable insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in projects:\n",
    "    plot_feature_impact(best_models[key], title ='Feature Impact for admission type id: %s' %key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploying the models\n",
    "Deploy the models as a REST API after which, we can make HTTP requests and get predictions back by using the deployment id!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_server = dr.PredictionServer.list()[0]\n",
    "\n",
    "for key in best_models:\n",
    "    temp_deployment = dr.Deployment.create_from_learning_model(\n",
    "                                    best_models[key].id, label='Readmissions_admission_type: %s' %key,\n",
    "                                    description='Test deployment',\n",
    "                                    default_prediction_server_id=prediction_server.id\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Through the API, the sky is the limit when it comes to what you can do: \n",
    "\n",
    "- You could monitor service performance (also available via UI)\n",
    "- You could motior accuracy performance (also available via UI)\n",
    "- You could retrain and update models (also available via UI)\n",
    "\n",
    "You could create a model factory that does all of the above based on rules you set and need minimum human intervention. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
