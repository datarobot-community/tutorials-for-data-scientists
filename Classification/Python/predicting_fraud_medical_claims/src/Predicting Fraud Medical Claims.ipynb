{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Fraud Medical Claims\n",
    "**Author**: Andrew Kruhko\n",
    "\n",
    "### Scope\n",
    "\n",
    "The scope of this notebook is to provide instructions on how to run a fraud medical claims use case with Python and DataRobot. The data is ingested through a database so you need to manipulate the code accordingly to fit your own needs but this serves as a prime example of how you can connect DataRobot to your own source systems. \n",
    "\n",
    "### Requirements\n",
    "\n",
    "- Python version 3.7.3\n",
    "-  DataRobot API version 2.19.0. \n",
    "Small adjustments might be needed depending on the Python version and DataRobot API version you are using.\n",
    "\n",
    "Full documentation of the Python package can be found here:Â https://datarobot-public-api-client.readthedocs-hosted.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries\n",
    "Importing libraries that will be used in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datarobot as dr\n",
    "import yaml\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to DataRobot\n",
    "Using <code>dr.Client</code> command alongside a yaml configuration file, we can connect to DataRobot. Alternatively, we could pass the <code>token</code> and <code>endpoint</code> variables to achieve the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.Client(config_path=\"../drconfig.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define some variables for later...\n",
    "Here we are defining some variables that will be used later in the analysis\n",
    "\n",
    "Yaml file description and required tags: \n",
    "- token: a DR API key\n",
    "- username: a login to DR\n",
    "- db_address: an IP or a server name\n",
    "- db_name: a database to connect with\n",
    "- db_user: a dadabase login\n",
    "- db_pass: a database password\n",
    "- pred_serv_id: a DR prediction server id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../drconfig.yaml\", 'r') as stream:\n",
    "    creds = yaml.safe_load(stream)\n",
    "token = creds['token']\n",
    "\n",
    "project_name = 'Medical_Insurance_Fraud'\n",
    "target = 'fraud'\n",
    "metric = 'LogLoss'\n",
    "\n",
    "base_url = 'YOUR_DATAROBOT_HOSTNAME'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Next Steps\n",
    "\n",
    "1. Create data sources\n",
    "    1. Find Microsoft SQL Server jdbc driver among predefined\n",
    "    2. Create a data store\n",
    "    3. Create a data source\n",
    "\n",
    "2. Create and run projects\n",
    "    1. Supervised models\n",
    "    2. Anomaly detection models\n",
    "    3. Supervised with anomaly detection features\n",
    "3. Compare results\n",
    "4. Deployment and scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dr_rest_call(url, req_func, payload=None):\n",
    "    headers = {'Authorization': f'Token {token}',\n",
    "               'Content-Type': 'application/json;charset=UTF-8'}\n",
    "    return req_func(f'{base_url}{url}', headers=headers, json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A Find Microsoft SQL Server jdbc driver among predefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = dr_rest_call('externalDataDrivers', requests.get)\n",
    "\n",
    "drivers = drivers.json()\n",
    "drivers_sql_serv = []\n",
    "for driver in drivers['data']:\n",
    "    if 'Microsoft SQL Server' in driver['canonicalName']:\n",
    "        drivers_sql_serv.append([driver['canonicalName'], driver['version'], driver['id']])\n",
    "drivers_sql_serv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the latest available driver\n",
    "driver_sql_serv_id = drivers_sql_serv[-1][-1]\n",
    "driver_sql_serv_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.B Create a data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'type': 'jdbc', \n",
    "        'canonicalName': 'sql_server_test', \n",
    "        'params': {'driverId': driver_sql_serv_id, \n",
    "                   'jdbcFields': \n",
    "                   [{'name': 'address', 'value': creds['db_address']},\n",
    "                    {'name': 'databaseName', 'value': creds['db_name']}]\n",
    "                  }}\n",
    "\n",
    "data_store_resp = dr_rest_call('externalDataStores', requests.post, payload=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YOUR_DATA_STORE_ID'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data store id\n",
    "data_store = data_store_resp.json()\n",
    "data_store_id = data_store['id']\n",
    "data_store_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.C Create a data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data source based on query \n",
    "ad_query = \"\"\"\n",
    "select *\n",
    "from drdemodb1.cfds_demo.Fraud_Medical_Insurance_Fraud\n",
    "order by npi\n",
    "\"\"\"\n",
    "data = {'type': 'jdbc', \n",
    "        'canonicalName': 'Medical_Insurance_Fraud_query', \n",
    "        'params': {'dataStoreId': data_store_id, \n",
    "                   'query': ad_query}}\n",
    "\n",
    "data_src_query_resp = dr_rest_call('externalDataSources', requests.post, payload=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_src_query = data_src_query_resp.json()\n",
    "data_src_query_id = data_src_query['id']\n",
    "data_src_query_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create and run projects\n",
    "We will be creating multiple functions that will be used later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_proj_id(resp):\n",
    "    \"\"\"\n",
    "    wait for the project creation\n",
    "    return the project id\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        resp_stat = requests.get(resp.headers['Location'], \n",
    "                                 headers={'Authorization': f'Token {token}', \n",
    "                                          'Content-Type': 'application/json;charset=UTF-8'})\n",
    "        resp_stat = resp_stat.json()\n",
    "\n",
    "        if resp_stat.get('id') is None:\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            proj_id = resp_stat.get('id')\n",
    "            break\n",
    "        \n",
    "    return proj_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_score(mod, metric):\n",
    "    res = {}\n",
    "    res['model_number'] = mod.model_number\n",
    "    res['model_type'] = mod.model_type\n",
    "    res['model_category'] = mod.model_category\n",
    "    res['model'] = mod\n",
    "    res['sample_pct'] = mod.sample_pct\n",
    "    \n",
    "    res['metric_v'] = mod.metrics.get(metric, {}).get('validation')\n",
    "    res['metric_cv'] = mod.metrics.get(metric, {}).get('crossValidation')\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_model_scores(proj, metric=None, ascending=True):\n",
    "    \"\"\"\n",
    "    iterate trough the project models and get their performance metric\n",
    "    \"\"\"\n",
    "    if metric is None:\n",
    "        metric = proj.metric        \n",
    "    df = pd.DataFrame([get_model_score(m, metric) for m in proj.get_models(with_metric=metric)])\n",
    "    return df.sort_values(['metric_cv', 'metric_v'], ascending=ascending, na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_preds(mod):\n",
    "    \"\"\"\n",
    "    request and/or retrieve training predictions for a given model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # request training predictions and get job ids\n",
    "        pred_job = mod.request_training_predictions(dr.enums.DATA_SUBSET.ALL)\n",
    "        preds = pred_job.get_result_when_complete().get_all_as_dataframe()\n",
    "        return preds\n",
    "    except:\n",
    "        # retrieve training predictions if they were already requested\n",
    "        train_preds = dr.TrainingPredictions.list(mod.project_id)\n",
    "        for train_pred in train_preds:\n",
    "            if train_pred.model_id == mod.id and train_pred.data_subset == 'all':\n",
    "                preds = dr.TrainingPredictions.get(mod.project_id, train_pred.prediction_id).get_all_as_dataframe()\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_ad_preds(mods):\n",
    "    \"\"\"\n",
    "    preprocess training predictions from anomaly detection models\n",
    "    mods - a list of aomaly detection models\n",
    "    \"\"\"\n",
    "    preds = get_train_preds(mods[0])\n",
    "    preds.set_index('row_id', inplace=True)\n",
    "    preds = preds[['partition_id', 'class_1.0']].copy()\n",
    "    preds.rename(columns={'class_1.0': f'{mods[0].model_type}_prediction'}, inplace=True)\n",
    "    for mod in mods[1:]:\n",
    "        preds_tmp = get_train_preds(mod)\n",
    "        preds_tmp.set_index('row_id', inplace=True)\n",
    "        preds = preds.merge(preds_tmp[['class_1.0']], left_index=True, right_index=True)\n",
    "        preds.rename(columns={'class_1.0': f'{mod.model_type}_prediction'}, inplace=True)\n",
    "        \n",
    "    preds['partition_id'] = preds.partition_id.replace('Holdout', '5.0').astype(float).astype(int)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.A Supervised Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a project based on the data source\n",
    "data = {'projectName': f'{project_name}_clf',\n",
    "        'dataSourceId': data_src_query_id, \n",
    "        'user': creds['db_user'],\n",
    "        'password': creds['db_pass']}\n",
    "\n",
    "project_clf_resp = dr_rest_call('projects', requests.post, payload=data)\n",
    "\n",
    "project_clf_id = wait_for_proj_id(project_clf_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the project trough python API \n",
    "projects = dr.Project.list()\n",
    "project_clf = [pr for pr in projects if pr.id == project_clf_id][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(Medical_Insurance_Fraud_clf)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set target and run autopilot\n",
    "project_clf.set_target(target=target,\n",
    "                       mode=dr.enums.AUTOPILOT_MODE.FULL_AUTO,\n",
    "                       metric=metric,\n",
    "                       worker_count=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_clf.wait_for_autopilot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.B Anomaly detection models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# select anomaly detection blueprints\n",
    "blueprints = project_clf.get_blueprints()\n",
    "blueprints = [bp for bp in blueprints if 'anomaly' in  bp.model_type.lower()]\n",
    "print(len(blueprints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 17:30:31.159688 start\n",
      "2020-04-11 17:34:36.464598 done\n"
     ]
    }
   ],
   "source": [
    "# unlock holdout\n",
    "project_clf.unlock_holdout()\n",
    "\n",
    "# train anomaly detection models\n",
    "print(str(datetime.now()), 'start')\n",
    "model_job_ids = []\n",
    "for bp in blueprints:\n",
    "    model_job_ids.append(project_clf.train(bp, sample_pct=100))\n",
    "    \n",
    "model_jobs = []\n",
    "for i in model_job_ids:\n",
    "    model_jobs.append(dr.ModelJob.get(project_clf_id, i))\n",
    "    \n",
    "for mj in model_jobs:\n",
    "    mj.wait_for_completion()\n",
    "print(str(datetime.now()), 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the leaderboard\n",
    "model_scores = get_model_scores(project_clf, metric='AUC', ascending=False)\n",
    "model_scores['is_ad'] = model_scores.model_type.apply(lambda x: 'anomaly' in x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_category</th>\n",
       "      <th>model</th>\n",
       "      <th>sample_pct</th>\n",
       "      <th>metric_v</th>\n",
       "      <th>metric_cv</th>\n",
       "      <th>is_ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>ENET Blender</td>\n",
       "      <td>blend</td>\n",
       "      <td>Model('ENET Blender')</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.74259</td>\n",
       "      <td>0.773014</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>120</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Light Gradient Boosting on ElasticNet P...</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.73000</td>\n",
       "      <td>0.772780</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>123</td>\n",
       "      <td>Advanced AVG Blender</td>\n",
       "      <td>blend</td>\n",
       "      <td>Model('Advanced AVG Blender')</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.73511</td>\n",
       "      <td>0.768186</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>AVG Blender</td>\n",
       "      <td>blend</td>\n",
       "      <td>Model('AVG Blender')</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.74596</td>\n",
       "      <td>0.767220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>ENET Blender</td>\n",
       "      <td>blend</td>\n",
       "      <td>Model('ENET Blender')</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.74456</td>\n",
       "      <td>0.767090</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Light Gradient Boosting on ElasticNet P...</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.74497</td>\n",
       "      <td>0.766502</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Light Gradient Boosting on ElasticNet P...</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.74298</td>\n",
       "      <td>0.763250</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>66</td>\n",
       "      <td>Nystroem Kernel SVM Classifier</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Nystroem Kernel SVM Classifier')</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.72758</td>\n",
       "      <td>0.763120</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>Elastic-Net Classifier (L2 / Binomial Deviance)</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Elastic-Net Classifier (L2 / Binomial D...</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.73225</td>\n",
       "      <td>0.759464</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>118</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Light Gradient Boosting on ElasticNet P...</td>\n",
       "      <td>80.00491</td>\n",
       "      <td>0.73110</td>\n",
       "      <td>0.752654</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_number                                         model_type  \\\n",
       "2            124                                       ENET Blender   \n",
       "10           120  Light Gradient Boosting on ElasticNet Predicti...   \n",
       "7            123                               Advanced AVG Blender   \n",
       "1            122                                        AVG Blender   \n",
       "0            125                                       ENET Blender   \n",
       "5             69  Light Gradient Boosting on ElasticNet Predicti...   \n",
       "4            111  Light Gradient Boosting on ElasticNet Predicti...   \n",
       "11            66                     Nystroem Kernel SVM Classifier   \n",
       "3             68    Elastic-Net Classifier (L2 / Binomial Deviance)   \n",
       "8            118  Light Gradient Boosting on ElasticNet Predicti...   \n",
       "\n",
       "   model_category                                              model  \\\n",
       "2           blend                              Model('ENET Blender')   \n",
       "10          model  Model('Light Gradient Boosting on ElasticNet P...   \n",
       "7           blend                      Model('Advanced AVG Blender')   \n",
       "1           blend                               Model('AVG Blender')   \n",
       "0           blend                              Model('ENET Blender')   \n",
       "5           model  Model('Light Gradient Boosting on ElasticNet P...   \n",
       "4           model  Model('Light Gradient Boosting on ElasticNet P...   \n",
       "11          model            Model('Nystroem Kernel SVM Classifier')   \n",
       "3           model  Model('Elastic-Net Classifier (L2 / Binomial D...   \n",
       "8           model  Model('Light Gradient Boosting on ElasticNet P...   \n",
       "\n",
       "    sample_pct  metric_v  metric_cv  is_ad  \n",
       "2     64.00393   0.74259   0.773014  False  \n",
       "10   100.00000   0.73000   0.772780  False  \n",
       "7     64.00393   0.73511   0.768186  False  \n",
       "1     64.00393   0.74596   0.767220  False  \n",
       "0     64.00393   0.74456   0.767090  False  \n",
       "5     64.00393   0.74497   0.766502  False  \n",
       "4     64.00393   0.74298   0.763250  False  \n",
       "11    64.00393   0.72758   0.763120  False  \n",
       "3     64.00393   0.73225   0.759464  False  \n",
       "8     80.00491   0.73110   0.752654  False  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blenders show slightly better results\n",
    "model_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_category</th>\n",
       "      <th>model</th>\n",
       "      <th>sample_pct</th>\n",
       "      <th>metric_v</th>\n",
       "      <th>metric_cv</th>\n",
       "      <th>is_ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>136</td>\n",
       "      <td>One-Class SVM Anomaly Detection</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('One-Class SVM Anomaly Detection')</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.57379</td>\n",
       "      <td>0.565596</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>131</td>\n",
       "      <td>Anomaly Detection with Supervised Learning (XGB)</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Anomaly Detection with Supervised Learn...</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.53977</td>\n",
       "      <td>0.563292</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>138</td>\n",
       "      <td>Local Outlier Factor Anomaly Detection</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Local Outlier Factor Anomaly Detection')</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.56287</td>\n",
       "      <td>0.552154</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>137</td>\n",
       "      <td>Anomaly Detection Blender</td>\n",
       "      <td>blend</td>\n",
       "      <td>Model('Anomaly Detection Blender')</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.48417</td>\n",
       "      <td>0.518688</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>135</td>\n",
       "      <td>Double Median Absolute Deviation Anomaly Detec...</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Double Median Absolute Deviation Anomal...</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.47252</td>\n",
       "      <td>0.516750</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>133</td>\n",
       "      <td>Isolation Forest Anomaly Detection</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Isolation Forest Anomaly Detection')</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.49861</td>\n",
       "      <td>0.498472</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>132</td>\n",
       "      <td>Mahalanobis Distance Ranked Anomaly Detection ...</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Mahalanobis Distance Ranked Anomaly Det...</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.50817</td>\n",
       "      <td>0.496544</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>134</td>\n",
       "      <td>Anomaly Detection with Supervised Learning (XGB)</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Anomaly Detection with Supervised Learn...</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.47885</td>\n",
       "      <td>0.487768</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>43</td>\n",
       "      <td>Isolation Forest Anomaly Detection</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Isolation Forest Anomaly Detection')</td>\n",
       "      <td>16.00099</td>\n",
       "      <td>0.48111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_number                                         model_type  \\\n",
       "80           136                    One-Class SVM Anomaly Detection   \n",
       "78           131   Anomaly Detection with Supervised Learning (XGB)   \n",
       "66           138             Local Outlier Factor Anomaly Detection   \n",
       "72           137                          Anomaly Detection Blender   \n",
       "77           135  Double Median Absolute Deviation Anomaly Detec...   \n",
       "75           133                 Isolation Forest Anomaly Detection   \n",
       "79           132  Mahalanobis Distance Ranked Anomaly Detection ...   \n",
       "73           134   Anomaly Detection with Supervised Learning (XGB)   \n",
       "76            43                 Isolation Forest Anomaly Detection   \n",
       "\n",
       "   model_category                                              model  \\\n",
       "80          model           Model('One-Class SVM Anomaly Detection')   \n",
       "78          model  Model('Anomaly Detection with Supervised Learn...   \n",
       "66          model    Model('Local Outlier Factor Anomaly Detection')   \n",
       "72          blend                 Model('Anomaly Detection Blender')   \n",
       "77          model  Model('Double Median Absolute Deviation Anomal...   \n",
       "75          model        Model('Isolation Forest Anomaly Detection')   \n",
       "79          model  Model('Mahalanobis Distance Ranked Anomaly Det...   \n",
       "73          model  Model('Anomaly Detection with Supervised Learn...   \n",
       "76          model        Model('Isolation Forest Anomaly Detection')   \n",
       "\n",
       "    sample_pct  metric_v  metric_cv  is_ad  \n",
       "80   100.00000   0.57379   0.565596   True  \n",
       "78   100.00000   0.53977   0.563292   True  \n",
       "66   100.00000   0.56287   0.552154   True  \n",
       "72   100.00000   0.48417   0.518688   True  \n",
       "77   100.00000   0.47252   0.516750   True  \n",
       "75   100.00000   0.49861   0.498472   True  \n",
       "79   100.00000   0.50817   0.496544   True  \n",
       "73   100.00000   0.47885   0.487768   True  \n",
       "76    16.00099   0.48111        NaN   True  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anomaly detection results aren't good but let's try to use them as features for supervised models\n",
    "model_scores[model_scores.is_ad].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.C Supervised with anomaly detection features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 17:36:23.304310 start\n",
      "2020-04-11 17:40:21.983410 done\n"
     ]
    }
   ],
   "source": [
    "# run anomaly detection blueprints on 64% of data to avoid the target leakage\n",
    "print(str(datetime.now()), 'start')\n",
    "model_job_ids = []\n",
    "for bp in blueprints:\n",
    "    model_job_ids.append(project_clf.train(bp, sample_pct=64.00393, scoring_type=dr.enums.SCORING_TYPE.cross_validation))\n",
    "    \n",
    "model_jobs = []\n",
    "for i in model_job_ids:\n",
    "    model_jobs.append(dr.ModelJob.get(project_clf_id, i))\n",
    "    \n",
    "for mj in model_jobs:\n",
    "    mj.wait_for_completion()\n",
    "print(str(datetime.now()), 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the leaderboard \n",
    "model_scores = get_model_scores(project_clf, metric='AUC', ascending=False)\n",
    "model_scores['is_ad'] = model_scores.model_type.apply(lambda x: 'anomaly' in x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_category</th>\n",
       "      <th>model</th>\n",
       "      <th>sample_pct</th>\n",
       "      <th>metric_v</th>\n",
       "      <th>metric_cv</th>\n",
       "      <th>is_ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>170</td>\n",
       "      <td>One-Class SVM Anomaly Detection</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('One-Class SVM Anomaly Detection')</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.56068</td>\n",
       "      <td>0.583700</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>182</td>\n",
       "      <td>Local Outlier Factor Anomaly Detection</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Local Outlier Factor Anomaly Detection')</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.54057</td>\n",
       "      <td>0.550668</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>140</td>\n",
       "      <td>Anomaly Detection with Supervised Learning (XGB)</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Anomaly Detection with Supervised Learn...</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.51358</td>\n",
       "      <td>0.549402</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>176</td>\n",
       "      <td>Anomaly Detection Blender</td>\n",
       "      <td>blend</td>\n",
       "      <td>Model('Anomaly Detection Blender')</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.49649</td>\n",
       "      <td>0.521904</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>164</td>\n",
       "      <td>Double Median Absolute Deviation Anomaly Detec...</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Double Median Absolute Deviation Anomal...</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.49306</td>\n",
       "      <td>0.518938</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_number                                         model_type  \\\n",
       "87           170                    One-Class SVM Anomaly Detection   \n",
       "64           182             Local Outlier Factor Anomaly Detection   \n",
       "83           140   Anomaly Detection with Supervised Learning (XGB)   \n",
       "75           176                          Anomaly Detection Blender   \n",
       "81           164  Double Median Absolute Deviation Anomaly Detec...   \n",
       "\n",
       "   model_category                                              model  \\\n",
       "87          model           Model('One-Class SVM Anomaly Detection')   \n",
       "64          model    Model('Local Outlier Factor Anomaly Detection')   \n",
       "83          model  Model('Anomaly Detection with Supervised Learn...   \n",
       "75          blend                 Model('Anomaly Detection Blender')   \n",
       "81          model  Model('Double Median Absolute Deviation Anomal...   \n",
       "\n",
       "    sample_pct  metric_v  metric_cv  is_ad  \n",
       "87    64.00393   0.56068   0.583700   True  \n",
       "64    64.00393   0.54057   0.550668   True  \n",
       "83    64.00393   0.51358   0.549402   True  \n",
       "75    64.00393   0.49649   0.521904   True  \n",
       "81    64.00393   0.49306   0.518938   True  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores[model_scores.is_ad & (model_scores.sample_pct < 100)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model('One-Class SVM Anomaly Detection'),\n",
       " Model('Local Outlier Factor Anomaly Detection'),\n",
       " Model('Anomaly Detection with Supervised Learning (XGB)')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select top n models\n",
    "models_n = 3\n",
    "models = model_scores[model_scores.is_ad & (model_scores.sample_pct < 100)].head(models_n).model.values.tolist()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 17:44:15.539194\n",
      "2020-04-11 17:46:44.567550\n"
     ]
    }
   ],
   "source": [
    "# get anomaly detection predictions\n",
    "print(str(datetime.now()))\n",
    "preds_ad = prep_ad_preds(models)\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12243, 17)\n",
      "(12243, 21)\n"
     ]
    }
   ],
   "source": [
    "# read the origonal dataset and add anomaly detection predictions\n",
    "df = pd.read_csv('data/DR_Demo_Medical_Fraud.csv')\n",
    "print(df.shape)\n",
    "\n",
    "df = df.merge(preds_ad, left_index=True, right_index=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(Medical_Insurance_Fraud_clf_ad)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create project with additional features and the same partitioning\n",
    "project_clf_ad = dr.Project.create(project_name=f'{project_name}_clf_ad', sourcedata=df)\n",
    "\n",
    "part = dr.UserCV(user_partition_col='partition_id', \n",
    "                 cv_holdout_level=5)\n",
    "project_clf_ad.set_target(target=target,\n",
    "                          mode=dr.enums.AUTOPILOT_MODE.FULL_AUTO,\n",
    "                          metric=metric,\n",
    "                          worker_count=-1, \n",
    "                          partitioning_method=part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_clf_ad.wait_for_autopilot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the leaderboard\n",
    "model_scores_ad = get_model_scores(project_clf_ad, metric='AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_category</th>\n",
       "      <th>model</th>\n",
       "      <th>sample_pct</th>\n",
       "      <th>metric_v</th>\n",
       "      <th>metric_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>ENET Blender</td>\n",
       "      <td>blend</td>\n",
       "      <td>Model('ENET Blender')</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.78126</td>\n",
       "      <td>0.775316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>123</td>\n",
       "      <td>AVG Blender</td>\n",
       "      <td>blend</td>\n",
       "      <td>Model('AVG Blender')</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.77029</td>\n",
       "      <td>0.770706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>ENET Blender</td>\n",
       "      <td>blend</td>\n",
       "      <td>Model('ENET Blender')</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.77036</td>\n",
       "      <td>0.770556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>73</td>\n",
       "      <td>Light Gradient Boosting on ElasticNet Predicti...</td>\n",
       "      <td>model</td>\n",
       "      <td>Model('Light Gradient Boosting on ElasticNet P...</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.76354</td>\n",
       "      <td>0.767978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>Advanced AVG Blender</td>\n",
       "      <td>blend</td>\n",
       "      <td>Model('Advanced AVG Blender')</td>\n",
       "      <td>64.00393</td>\n",
       "      <td>0.77917</td>\n",
       "      <td>0.766440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_number                                         model_type  \\\n",
       "0            125                                       ENET Blender   \n",
       "5            123                                        AVG Blender   \n",
       "4            126                                       ENET Blender   \n",
       "10            73  Light Gradient Boosting on ElasticNet Predicti...   \n",
       "1            124                               Advanced AVG Blender   \n",
       "\n",
       "   model_category                                              model  \\\n",
       "0           blend                              Model('ENET Blender')   \n",
       "5           blend                               Model('AVG Blender')   \n",
       "4           blend                              Model('ENET Blender')   \n",
       "10          model  Model('Light Gradient Boosting on ElasticNet P...   \n",
       "1           blend                      Model('Advanced AVG Blender')   \n",
       "\n",
       "    sample_pct  metric_v  metric_cv  \n",
       "0     64.00393   0.78126   0.775316  \n",
       "5     64.00393   0.77029   0.770706  \n",
       "4     64.00393   0.77036   0.770556  \n",
       "10    64.00393   0.76354   0.767978  \n",
       "1     64.00393   0.77917   0.766440  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores_ad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf = dr.ModelRecommendation.get(project_clf.id).get_model()\n",
    "model_clf_ad = dr.ModelRecommendation.get(project_clf_ad.id).get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC supervised                      : 0.77278\n",
      "AUC supervised with anomaly features: 0.765288\n",
      "LogLoss supervised                      : 0.16669399999999998\n",
      "LogLoss supervised with anomaly features: 0.167132\n"
     ]
    }
   ],
   "source": [
    "# recommended models results\n",
    "print('AUC supervised                      :', model_clf.metrics['AUC']['crossValidation'])\n",
    "print('AUC supervised with anomaly features:', model_clf_ad.metrics['AUC']['crossValidation'])\n",
    "\n",
    "print('LogLoss supervised                      :', model_clf.metrics['LogLoss']['crossValidation'])\n",
    "print('LogLoss supervised with anomaly features:', model_clf_ad.metrics['LogLoss']['crossValidation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Deployment and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_deployment(data, datarobot_key, deployment_url, deployment_id):\n",
    "    # Set HTTP headers. The charset should match the contents of the file.\n",
    "    headers = {'Content-Type': 'application/json; charset=UTF-8', 'datarobot-key': datarobot_key}\n",
    "\n",
    "    url = f'{deployment_url}/predApi/v1.0/deployments/{deployment_id}/predictions'\n",
    "    \n",
    "    # Make API request for predictions\n",
    "    predictions_response = requests.post(\n",
    "        url,\n",
    "        auth=(creds['username'], creds['token']),\n",
    "        data=data,\n",
    "        headers=headers,\n",
    "    )\n",
    "\n",
    "    return predictions_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_deployment_expl(data, datarobot_key, deployment_url, deployment_id):\n",
    "    # Set HTTP headers. The charset should match the contents of the file.\n",
    "    headers = {'Content-Type': 'application/json; charset=UTF-8', 'datarobot-key': datarobot_key}\n",
    "    \n",
    "    # prediction explanations parameters\n",
    "    params = {\n",
    "            'maxCodes': 3,\n",
    "            'thresholdHigh': 0.1,\n",
    "            'thresholdLow': 0.01,\n",
    "        }\n",
    "    \n",
    "    url = f'{deployment_url}/predApi/v1.0/deployments/{deployment_id}/predictionExplanations'\n",
    "    \n",
    "    # Make API request for predictions\n",
    "    predictions_response = requests.post(\n",
    "        url,\n",
    "        auth=(creds['username'], creds['token']),\n",
    "        data=data,\n",
    "        headers=headers,\n",
    "        params=params\n",
    "    )\n",
    "\n",
    "    return predictions_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(y):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute feature impact\n",
    "feature_impacts = model_clf.get_or_request_feature_impact()\n",
    "\n",
    "# initialize prediction explanations\n",
    "pei_job = dr.PredictionExplanationsInitialization.create(project_clf.id, model_clf.id)\n",
    "pei_job.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the model\n",
    "deployment = dr.Deployment.create_from_learning_model(model_id=model_clf.id, \n",
    "                                                      label=f'{project_name}_clf_depl',\n",
    "                                                      default_prediction_server_id=creds['pred_serv_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction server url, deployment id and DataRobot key\n",
    "pred_server = deployment.default_prediction_server\n",
    "\n",
    "dr_key = pred_server['datarobot-key']\n",
    "depl_url = pred_server['url']\n",
    "depl_id = deployment.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 18)\n"
     ]
    }
   ],
   "source": [
    "# read and prepare a dataset to score\n",
    "df_scoring = pd.read_csv('data/DR_Demo_Medical_Fraud_scoring.csv')\n",
    "print(df_scoring.shape)\n",
    "data_to_pred = json.dumps(df_scoring.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 18:55:09.722345\n",
      "2020-04-11 19:02:09.550274\n"
     ]
    }
   ],
   "source": [
    "# get and precess predictions with explanations\n",
    "print(str(datetime.now()))\n",
    "preds_raw = predict_deployment_expl(data_to_pred, dr_key, depl_url, depl_id)\n",
    "\n",
    "df_preds = pd.DataFrame()\n",
    "for row in preds_raw['data']:\n",
    "    new_row = pd.json_normalize(data=flatten_json(row))\n",
    "    df_preds = pd.concat([df_preds, new_row])\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rename = {'predictionValues_0_value': 'Prediction', \n",
    "                  'predictionExplanations_0_feature': 'Primary Feature',\n",
    "                  'predictionExplanations_0_featureValue': 'Primary Feature Value',\n",
    "                  'predictionExplanations_0_qualitativeStrength':'Primary Feature Strength',\n",
    "                  \n",
    "                  'predictionExplanations_1_feature': 'Secondary Feature',\n",
    "                  'predictionExplanations_1_featureValue': 'Secondary Feature Value',\n",
    "                  'predictionExplanations_1_qualitativeStrength':'Secondary Feature Strength',\n",
    "                  \n",
    "                  'predictionExplanations_2_feature': 'Tertiary Feature',\n",
    "                  'predictionExplanations_2_featureValue': 'Tertiary Feature Value',\n",
    "                  'predictionExplanations_2_qualitativeStrength':'Tertiary Feature Strength'}\n",
    "\n",
    "df_preds.rename(columns=cols_to_rename, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 18) (20000, 22)\n",
      "(20000, 29)\n"
     ]
    }
   ],
   "source": [
    "print(df_scoring.shape, df_preds.shape)\n",
    "cols_to_add = ['rowId', 'Prediction', \n",
    "               'Primary Feature Value', 'Primary Feature Strength', 'Primary Feature', \n",
    "               'Secondary Feature Value', 'Secondary Feature Strength', 'Secondary Feature',\n",
    "               'Tertiary Feature Value', 'Tertiary Feature Strength', 'Tertiary Feature',\n",
    "              ]\n",
    "df_scoring = df_scoring.merge(df_preds[cols_to_add], on='rowId')\n",
    "df_scoring['Prediction Category'] = df_scoring.Prediction.apply(lambda x:\n",
    "                                                                'High' if x >= 0.2 else\n",
    "                                                                'Medium' if x >= 0.1 else 'Low')\n",
    "print(df_scoring.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to use for a dashboard preparation\n",
    "df_scoring.to_csv('data/DR_Demo_Medical_Fraud_scoring_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
